{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceType":"datasetVersion","sourceId":1351797,"datasetId":786787,"databundleVersionId":1384195},{"sourceType":"datasetVersion","sourceId":10254752,"datasetId":6343395,"databundleVersionId":10552082}],"dockerImageVersionId":30826,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"msambare/fer2013\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T12:38:27.033220Z","iopub.execute_input":"2024-12-20T12:38:27.033897Z","iopub.status.idle":"2024-12-20T12:38:29.196705Z","shell.execute_reply.started":"2024-12-20T12:38:27.033861Z","shell.execute_reply":"2024-12-20T12:38:29.196069Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"},{"name":"stdout","text":"Path to dataset files: /kaggle/input/d/msambare/fer2013\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport cv2 as cv\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nfrom sklearn.utils import class_weight\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nimport pathlib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T12:38:43.055644Z","iopub.execute_input":"2024-12-20T12:38:43.056269Z","iopub.status.idle":"2024-12-20T12:39:03.079615Z","shell.execute_reply.started":"2024-12-20T12:38:43.056236Z","shell.execute_reply":"2024-12-20T12:39:03.078514Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1734698335.807714      13 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD1220 12:38:55.816193440      13 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD1220 12:38:55.816207849      13 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD1220 12:38:55.816211046      13 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD1220 12:38:55.816213367      13 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD1220 12:38:55.816215702      13 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD1220 12:38:55.816218027      13 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD1220 12:38:55.816220235      13 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD1220 12:38:55.816222422      13 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD1220 12:38:55.816224595      13 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD1220 12:38:55.816226733      13 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD1220 12:38:55.816228890      13 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD1220 12:38:55.816231085      13 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD1220 12:38:55.816233205      13 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD1220 12:38:55.816235382      13 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD1220 12:38:55.816237483      13 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD1220 12:38:55.816239627      13 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD1220 12:38:55.816241905      13 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD1220 12:38:55.816244112      13 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD1220 12:38:55.816246272      13 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD1220 12:38:55.816248487      13 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD1220 12:38:55.816250615      13 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD1220 12:38:55.816252802      13 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD1220 12:38:55.816255035      13 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD1220 12:38:55.816257244      13 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD1220 12:38:55.816259315      13 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD1220 12:38:55.816261441      13 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD1220 12:38:55.816263649      13 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD1220 12:38:55.816265849      13 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD1220 12:38:55.816268100      13 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD1220 12:38:55.816271597      13 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD1220 12:38:55.816273922      13 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD1220 12:38:55.816276251      13 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD1220 12:38:55.816278925      13 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD1220 12:38:55.816281170      13 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD1220 12:38:55.816283340      13 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD1220 12:38:55.816285526      13 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD1220 12:38:55.816287642      13 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD1220 12:38:55.816289816      13 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD1220 12:38:55.816292060      13 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD1220 12:38:55.816294269      13 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD1220 12:38:55.816296425      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD1220 12:38:55.816298565      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD1220 12:38:55.816300747      13 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD1220 12:38:55.816302990      13 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD1220 12:38:55.816305241      13 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI1220 12:38:55.816480465      13 ev_epoll1_linux.cc:123]               grpc epoll fd: 61\nD1220 12:38:55.816492359      13 ev_posix.cc:113]                      Using polling engine: epoll1\nD1220 12:38:55.826915848      13 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD1220 12:38:55.826927277      13 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD1220 12:38:55.826934721      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD1220 12:38:55.826937896      13 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD1220 12:38:55.826940916      13 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD1220 12:38:55.826943764      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD1220 12:38:55.826970924      13 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD1220 12:38:55.826985151      13 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD1220 12:38:55.827000609      13 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD1220 12:38:55.827021442      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD1220 12:38:55.827028330      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD1220 12:38:55.827031504      13 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD1220 12:38:55.827035419      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD1220 12:38:55.827038527      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD1220 12:38:55.827044388      13 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD1220 12:38:55.827047574      13 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD1220 12:38:55.827077238      13 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI1220 12:38:55.844831933      13 ev_epoll1_linux.cc:359]               grpc epoll fd: 63\nI1220 12:38:55.845997357      13 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI1220 12:38:55.849301776     171 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI1220 12:38:55.849360786     171 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE1220 12:38:55.854923179     167 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-12-20T12:38:55.854906027+00:00\", grpc_status:2}\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T12:39:03.081136Z","iopub.execute_input":"2024-12-20T12:39:03.081639Z","iopub.status.idle":"2024-12-20T12:39:12.264446Z","shell.execute_reply.started":"2024-12-20T12:39:03.081610Z","shell.execute_reply":"2024-12-20T12:39:12.263596Z"}},"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1734698347.106727      13 service.cc:145] XLA service 0x5c856748d260 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1734698347.106781      13 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1734698347.106785      13 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1734698347.106788      13 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1734698347.106809      13 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1734698347.106813      13 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1734698347.106815      13 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1734698347.106818      13 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1734698347.106821      13 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"TRAIN_PATH = pathlib.Path('/kaggle/input/fer2013/FER2013-down_sampling_augmented')\nTEST_PATH = pathlib.Path('/kaggle/input/d/msambare/fer2013/test')\nLABEL_NAMES = [\"angry\", \"fear\", \"happy\", \"neutral\", \"sad\", \"surprise\"]\nNUM_CLASSES = len(LABEL_NAMES)\nBATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\nIMG_SIZE = (224,224)\nAUTOTUNE = tf.data.AUTOTUNE\nIMG_SHAPE = IMG_SIZE + (3,)\nVALIDATION_SPLIT = 0.2\nSEED = 42\nSHUFFLE = True\n\nLABEL_INDICES = [i for i in range(0, NUM_CLASSES)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T12:40:24.517694Z","iopub.execute_input":"2024-12-20T12:40:24.518033Z","iopub.status.idle":"2024-12-20T12:40:24.523373Z","shell.execute_reply.started":"2024-12-20T12:40:24.518003Z","shell.execute_reply":"2024-12-20T12:40:24.522486Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def preprocess_augmented(image, label):\n    image = tf.image.resize(image, IMG_SIZE)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.random_flip_left_right(image)\n    return image, label\n\ndef preprocess(image, label):\n    image = tf.image.resize(image, IMG_SIZE)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    return image, label\n\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    TRAIN_PATH,\n    validation_split=VALIDATION_SPLIT,\n    subset='training',\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_names=LABEL_NAMES\n)\n\nval_ds = tf.keras.utils.image_dataset_from_directory(\n    TRAIN_PATH,\n    validation_split=VALIDATION_SPLIT,\n    subset='validation',\n    seed=SEED,\n    image_size=IMG_SIZE,\n    batch_size=BATCH_SIZE,\n    class_names=LABEL_NAMES\n)\n\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    TEST_PATH,\n    image_size=IMG_SIZE,\n    class_names=LABEL_NAMES\n)\n\ntrain_ds = train_ds.map(preprocess_augmented, num_parallel_calls=tf.data.AUTOTUNE).shuffle(1000).prefetch(tf.data.AUTOTUNE)\nval_ds = val_ds.map(preprocess, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\ntest_ds = test_ds.map(preprocess)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-20T12:40:25.331981Z","iopub.execute_input":"2024-12-20T12:40:25.332728Z","iopub.status.idle":"2024-12-20T12:40:45.074302Z","shell.execute_reply.started":"2024-12-20T12:40:25.332691Z","shell.execute_reply":"2024-12-20T12:40:45.073397Z"}},"outputs":[{"name":"stdout","text":"Found 72000 files belonging to 6 classes.\nUsing 57600 files for training.\nFound 72000 files belonging to 6 classes.\nUsing 14400 files for validation.\nFound 7067 files belonging to 6 classes.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"base_learning_rate = 0.0001\n# base_learning_rate = 0.01\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=base_learning_rate,\n    decay_steps=10000,\n    decay_rate=0.96,\n    staircase=True\n)\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n\nwith tpu_strategy.scope():\n    inputs = tf.keras.Input(shape=IMG_SHAPE)\n    preprocess_input = tf.keras.applications.resnet.preprocess_input\n    base_model = tf.keras.applications.ResNet50(\n        include_top=False,\n        weights='imagenet',\n        input_shape=IMG_SHAPE\n    )\n    global_average = tf.keras.layers.GlobalAveragePooling2D()\n    add_layer = tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01))\n    dense_layer = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')\n    base_model.trainable = False\n\n    x = preprocess_input(inputs)\n    x = base_model(x, training=False)\n    x = global_average(x)\n    outputs = dense_layer(x)\n    model = tf.keras.Model(inputs, outputs)\n    model.summary()\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                  metrics=['accuracy'])\n\n    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(LABEL_INDICES), y=LABEL_INDICES)\n    class_weight_dict = dict(enumerate(class_weights))\n\n    initial_epochs = 20\n    history = model.fit(train_ds,\n                        epochs=initial_epochs,\n                        validation_data=val_ds,\n                        class_weight=class_weight_dict,\n                       callbacks=[early_stopping])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"base_model.trainable = True\nbase_learning_rate = 0.00001\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=base_learning_rate,\n    decay_steps=100000,\n    decay_rate=0.96,\n    staircase=True\n)\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=2, restore_best_weights=True)\n\nwith tpu_strategy.scope():\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                  metrics=['accuracy'])\n    \n    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(LABEL_INDICES), y=LABEL_INDICES)\n    class_weight_dict = dict(enumerate(class_weights))\n    \n    fine_tune_epochs = 10\n    total_epochs =  initial_epochs + fine_tune_epochs\n    \n    history_fine = model.fit(train_ds,\n                             epochs=total_epochs,\n                             initial_epoch=len(history.epoch),\n                             validation_data=val_ds,\n                            callbacks=[early_stopping])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images_ = []\nlabels_ = []\n\nfor images, labels in test_ds:\n    for img in images:\n        images_.append(img.numpy())\n    for label in labels:\n        labels_.append(label.numpy())\n\nimages_np = np.array(images_)\n\npred = model.predict(images_np)\n\npred_res = []\nfor p in pred:\n    pred_res.append(np.argmax(p))\n\nprint(accuracy_score(labels_[:7066], pred_res))","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}