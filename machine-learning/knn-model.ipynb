{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IdjiotSandwiches/face-emotion-recognition/blob/knn-model/machine-learning/knn-model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6hUfuo0aRiN",
        "outputId": "97e77e90-0d66-4399-ad16-a1dd7f28a76f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m252.5/252.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m203.2/203.2 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m74.0/74.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m27.4/27.4 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m623.0/623.0 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install dagshub --quiet\n",
        "!pip install mlflow --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-qnEnkZZokh9"
      },
      "outputs": [],
      "source": [
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import dagshub\n",
        "import os\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w7tVMC6k2d_C"
      },
      "outputs": [],
      "source": [
        "PATH = pathlib.Path('C:\\\\Users\\\\vinar\\\\Downloads\\\\FER2013-augmented')\n",
        "LABELS = os.listdir(PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211,
          "referenced_widgets": [
            "920e17e50eb74233a60169339897c634",
            "4d8ec34e0e8b46eea1f0c715cc9a0313"
          ]
        },
        "id": "0_ZIM-8six15",
        "outputId": "573ac8c8-c9b2-4911-9ea6-c8d32b0274db"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as IdjiotSandwiches\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Accessing as IdjiotSandwiches\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"IdjiotSandwiches/face-emotion-recognition\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"IdjiotSandwiches/face-emotion-recognition\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository IdjiotSandwiches/face-emotion-recognition initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository IdjiotSandwiches/face-emotion-recognition initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dagshub.init(repo_owner='IdjiotSandwiches', repo_name='face-emotion-recognition', mlflow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "dkTt8IV6c82R"
      },
      "outputs": [],
      "source": [
        "K_SIZE = (21,21)\n",
        "SIGMA = 3\n",
        "THETA_RANGE = np.arange(0, np.pi, np.pi/32)\n",
        "LAMBD = 10.0\n",
        "GAMMA = 0.5\n",
        "PSI = 0\n",
        "FLOATING_POINT = cv.CV_32F\n",
        "IMAGE_SIZE = (48,48)\n",
        "N_COMPONENTS = 0.95\n",
        "N_COMPONENTS_LOCAL = 16\n",
        "BLUR = (5,5)\n",
        "\n",
        "gabor_params = {\n",
        "    'ksize': K_SIZE,\n",
        "    'sigma': SIGMA,\n",
        "    'lambd': LAMBD,\n",
        "    'gamma': GAMMA,\n",
        "    'psi': PSI\n",
        "}\n",
        "\n",
        "KERNELS = [cv.getGaborKernel(**gabor_params, theta=theta) for theta in THETA_RANGE]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PsHCDjtqckSM"
      },
      "outputs": [],
      "source": [
        "def gabor_filter(img):\n",
        "  img = img.astype(np.float32)\n",
        "  return np.array([cv.filter2D(img, FLOATING_POINT, kernel) for kernel in KERNELS])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "np5MQV1Spe5A"
      },
      "outputs": [],
      "source": [
        "def save_filtered_img(images, labels, path):\n",
        "  folder_path = f'C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\{path}'\n",
        "  os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "  np.save(f'{folder_path}/images.npy', images)\n",
        "  np.save(f'{folder_path}/labels.npy', labels)\n",
        "\n",
        "  print('Ok!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed\n",
        "\n",
        "def process_image(img_path, label, dir):\n",
        "    \"\"\"\n",
        "    Process a single image: read, preprocess, and apply PCA.\n",
        "    \"\"\"\n",
        "    path = f'{dir}/{label}'\n",
        "    img = cv.imread(f'{path}/{img_path}', 0)\n",
        "    img = cv.resize(img, IMAGE_SIZE)\n",
        "    img = cv.GaussianBlur(img, BLUR, 0)\n",
        "    img = cv.equalizeHist(img)\n",
        "\n",
        "    face_cascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "    faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=5, minSize=(50, 50))\n",
        "\n",
        "    if len(faces) > 0:\n",
        "        x, y, w, h = faces[0]\n",
        "        img = img[y:y+h, x:x+w]\n",
        "    else:\n",
        "        h, w = img.shape[:2]\n",
        "        crop_size = min(h, w)\n",
        "        x = (w - crop_size) // 2\n",
        "        y = (h - crop_size) // 2\n",
        "        img = img[y:y+crop_size, x:x+crop_size]\n",
        "    \n",
        "    img = cv.copyMakeBorder(\n",
        "        img, \n",
        "        10, 10, 10, 10,\n",
        "        cv.BORDER_CONSTANT, \n",
        "        value=(0, 0, 0)\n",
        "    )\n",
        "    \n",
        "    img = cv.resize(img, IMAGE_SIZE)\n",
        "    img = img / 255.0\n",
        "    img = gabor_filter(img)\n",
        "\n",
        "    img = img.reshape(img.shape[0], -1)\n",
        "    pca = PCA(n_components=N_COMPONENTS_LOCAL)\n",
        "    img = pca.fit_transform(img)\n",
        "\n",
        "    folder_path = f'C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\FER2013\\\\new\\\\{label}'\n",
        "    os.makedirs(folder_path, exist_ok=True)\n",
        "    img_path = img_path.split('.')\n",
        "    np.save(f'{folder_path}/{img_path[0]}.npy', img)\n",
        "\n",
        "\n",
        "def open_dataset(dir):\n",
        "    \"\"\"\n",
        "    Open dataset, load images, preprocess, and return images and labels using parallel processing.\n",
        "    \"\"\"\n",
        "    # Use Parallel from joblib to process images in parallel\n",
        "    results = Parallel(n_jobs=4)(delayed(process_image)(img_path, label, dir)\n",
        "                                   for label in LABELS\n",
        "                                   for img_path in tqdm(os.listdir(f'{dir}/{label}')))\n",
        "\n",
        "    # Unzip the results into images and labels\n",
        "    # images, labels = zip(*results)\n",
        "\n",
        "    # return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg7Y6GAw2X73",
        "outputId": "5514be04-743d-42c0-fbc9-a04b9331d5e1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [01:59<00:00, 100.74it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [02:09<00:00, 92.78it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [02:07<00:00, 94.41it/s] \n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [01:59<00:00, 100.69it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [02:02<00:00, 97.79it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [02:10<00:00, 91.81it/s] \n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable NoneType object",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m images, labels \u001b[38;5;241m=\u001b[39m open_dataset(PATH)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# save_filtered_img(images, labels, 'FER2013/new')\u001b[39;00m\n",
            "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ],
      "source": [
        "images, labels = open_dataset(PATH)\n",
        "# save_filtered_img(images, labels, 'FER2013/new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [01:16<00:00, 157.13it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [01:15<00:00, 158.20it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [01:18<00:00, 152.43it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [01:19<00:00, 150.96it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [01:21<00:00, 148.06it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12000/12000 [01:16<00:00, 157.81it/s]\n"
          ]
        }
      ],
      "source": [
        "images = []\n",
        "labels = []\n",
        "folder = 'C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\FER2013\\\\new'\n",
        "LABELS = os.listdir(folder)\n",
        "for label in LABELS:\n",
        "    class_folder = f'{folder}/{label}'\n",
        "    for img_path in tqdm(os.listdir(class_folder)):\n",
        "        img = np.load(f'{class_folder}/{img_path}')\n",
        "        images.append(img)\n",
        "        labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Explained variance ratio: [0.47909495 0.29831967 0.07858441 0.06036508 0.02089529 0.01489168]\n",
            "Cumulative explained variance: [0.47909495 0.7774146  0.85599905 0.91636413 0.93725944 0.9521511 ]\n",
            "(72000, 6)\n"
          ]
        }
      ],
      "source": [
        "images = images.reshape(images.shape[0], -1)\n",
        "pca = PCA(n_components=N_COMPONENTS)\n",
        "images_ = pca.fit_transform(images)\n",
        "\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
        "print(\"Cumulative explained variance:\", np.cumsum(pca.explained_variance_ratio_))\n",
        "print(images_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ok!\n"
          ]
        }
      ],
      "source": [
        "save_filtered_img(images_, labels, 'FER2013/combined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ok!\n"
          ]
        }
      ],
      "source": [
        "test_images, test_labels = open_dataset(f'{PATH}/test')\n",
        "save_filtered_img(test_images, test_labels, 'test')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOHtUKOCBYCM"
      },
      "source": [
        "## **Testing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XXABw7w8XG_",
        "outputId": "70ccb1dc-d9ba-43aa-8dd4-7093a0093995"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.40302267002518893\n",
            "Precision: 0.41299608247524017\n",
            "Recall: 0.4048097415362125\n",
            "F1 Score: 0.4061926739713124\n",
            "AUC Score: 0.7423581160105994\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.43      0.34      0.38       661\n",
            "     disgust       0.55      0.46      0.50       535\n",
            "        fear       0.40      0.37      0.39       634\n",
            "       happy       0.36      0.38      0.37       633\n",
            "     neutral       0.32      0.42      0.36       621\n",
            "         sad       0.41      0.39      0.40       652\n",
            "    surprise       0.41      0.47      0.44       631\n",
            "\n",
            "    accuracy                           0.40      4367\n",
            "   macro avg       0.41      0.40      0.41      4367\n",
            "weighted avg       0.41      0.40      0.40      4367\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/12/16 20:54:13 INFO mlflow.tracking.fluent: Experiment with name 'KNN_Model FER2013 augmented' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e11e5e1e45244062911bfee362d25a4e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=0 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/e7ba29bcac2a4fe386bc657e01781808\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.393405083581406\n",
            "Precision: 0.4019841855378405\n",
            "Recall: 0.39641527564110923\n",
            "F1 Score: 0.39701216058685024\n",
            "AUC Score: 0.7386236439677767\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.42      0.32      0.36       661\n",
            "     disgust       0.54      0.50      0.52       535\n",
            "        fear       0.35      0.39      0.37       634\n",
            "       happy       0.38      0.38      0.38       633\n",
            "     neutral       0.32      0.39      0.35       621\n",
            "         sad       0.40      0.35      0.37       652\n",
            "    surprise       0.41      0.45      0.43       631\n",
            "\n",
            "    accuracy                           0.39      4367\n",
            "   macro avg       0.40      0.40      0.40      4367\n",
            "weighted avg       0.40      0.39      0.39      4367\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "681bf3f2bdd14adaa6099cce34a22b83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=1 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/e683b158690b4008aa06cd0d68f73829\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3847034577513167\n",
            "Precision: 0.39281919756271383\n",
            "Recall: 0.3878716270835458\n",
            "F1 Score: 0.3875802950607442\n",
            "AUC Score: 0.7348155978680045\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.39      0.31      0.34       661\n",
            "     disgust       0.53      0.49      0.51       535\n",
            "        fear       0.41      0.34      0.37       634\n",
            "       happy       0.33      0.35      0.34       633\n",
            "     neutral       0.31      0.41      0.35       621\n",
            "         sad       0.37      0.33      0.35       652\n",
            "    surprise       0.42      0.49      0.45       631\n",
            "\n",
            "    accuracy                           0.38      4367\n",
            "   macro avg       0.39      0.39      0.39      4367\n",
            "weighted avg       0.39      0.38      0.38      4367\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3f8acdadbe04d7cbe9de0344b6bde9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=2 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/a71fb4ec80224eae9b0cfa129d24baaf\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.39867185711014425\n",
            "Precision: 0.40590718947518434\n",
            "Recall: 0.4025302870846642\n",
            "F1 Score: 0.401864305810431\n",
            "AUC Score: 0.7387189929033056\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.40      0.31      0.35       661\n",
            "     disgust       0.57      0.53      0.55       535\n",
            "        fear       0.36      0.41      0.38       634\n",
            "       happy       0.36      0.33      0.34       633\n",
            "     neutral       0.34      0.43      0.38       621\n",
            "         sad       0.39      0.34      0.36       652\n",
            "    surprise       0.42      0.46      0.44       631\n",
            "\n",
            "    accuracy                           0.40      4367\n",
            "   macro avg       0.41      0.40      0.40      4367\n",
            "weighted avg       0.40      0.40      0.40      4367\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab88c37198f54ed5be0da95f06649192",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=3 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/9349ac7d8bee4da1aa84e95d95ffbd4f\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3824135562170827\n",
            "Precision: 0.39194578869339003\n",
            "Recall: 0.3856033417290564\n",
            "F1 Score: 0.3869158146330626\n",
            "AUC Score: 0.7302916702179304\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.42      0.34      0.37       661\n",
            "     disgust       0.56      0.50      0.53       535\n",
            "        fear       0.37      0.43      0.40       634\n",
            "       happy       0.35      0.37      0.36       633\n",
            "     neutral       0.29      0.35      0.31       621\n",
            "         sad       0.36      0.31      0.33       652\n",
            "    surprise       0.41      0.41      0.41       631\n",
            "\n",
            "    accuracy                           0.38      4367\n",
            "   macro avg       0.39      0.39      0.39      4367\n",
            "weighted avg       0.39      0.38      0.38      4367\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ed8eee09bf24c199cd9fdbe00c0bb63",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=4 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/3128b0c46d3b4a1f8137bbaf61378afe\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3983050847457627\n",
            "Precision: 0.4081823252162809\n",
            "Recall: 0.40157926580685654\n",
            "F1 Score: 0.40210514000592573\n",
            "AUC Score: 0.7469229932104579\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.39      0.33      0.36       661\n",
            "     disgust       0.53      0.51      0.52       534\n",
            "        fear       0.36      0.39      0.38       634\n",
            "       happy       0.40      0.39      0.39       634\n",
            "     neutral       0.31      0.43      0.36       620\n",
            "         sad       0.44      0.34      0.38       653\n",
            "    surprise       0.42      0.42      0.42       630\n",
            "\n",
            "    accuracy                           0.40      4366\n",
            "   macro avg       0.41      0.40      0.40      4366\n",
            "weighted avg       0.41      0.40      0.40      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19c2e9cda7124c1facc61028424a8d19",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=5 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/14b06e579a264caab691033399c45ceb\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.39395327530920754\n",
            "Precision: 0.4046027531188448\n",
            "Recall: 0.39636421076740774\n",
            "F1 Score: 0.39737053097196096\n",
            "AUC Score: 0.7378721349462476\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.45      0.35      0.39       661\n",
            "     disgust       0.54      0.48      0.51       534\n",
            "        fear       0.35      0.39      0.37       634\n",
            "       happy       0.36      0.39      0.37       634\n",
            "     neutral       0.33      0.38      0.35       620\n",
            "         sad       0.42      0.33      0.37       653\n",
            "    surprise       0.38      0.47      0.42       630\n",
            "\n",
            "    accuracy                           0.39      4366\n",
            "   macro avg       0.40      0.40      0.40      4366\n",
            "weighted avg       0.40      0.39      0.39      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b618b5e2f4a64c299254e5f09723f3cd",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=6 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/a063c47a3950403d90ed536606f1a108\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3891433806688044\n",
            "Precision: 0.3985447061047867\n",
            "Recall: 0.3927910611243136\n",
            "F1 Score: 0.39234436697017505\n",
            "AUC Score: 0.746402252541727\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.41      0.30      0.35       661\n",
            "     disgust       0.53      0.51      0.52       534\n",
            "        fear       0.36      0.40      0.38       634\n",
            "       happy       0.37      0.39      0.38       634\n",
            "     neutral       0.31      0.43      0.36       620\n",
            "         sad       0.40      0.33      0.36       653\n",
            "    surprise       0.41      0.40      0.40       630\n",
            "\n",
            "    accuracy                           0.39      4366\n",
            "   macro avg       0.40      0.39      0.39      4366\n",
            "weighted avg       0.40      0.39      0.39      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c7224a604dc4c3fb8f9619b0c8e0a1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=7 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/e659316f87d24fedb51e302f4df5d81c\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3813559322033898\n",
            "Precision: 0.3892892263651859\n",
            "Recall: 0.38479309218235624\n",
            "F1 Score: 0.3850652420980702\n",
            "AUC Score: 0.7331348812305959\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.40      0.33      0.36       661\n",
            "     disgust       0.53      0.50      0.51       534\n",
            "        fear       0.35      0.35      0.35       634\n",
            "       happy       0.35      0.37      0.36       634\n",
            "     neutral       0.30      0.40      0.35       620\n",
            "         sad       0.38      0.31      0.34       653\n",
            "    surprise       0.42      0.43      0.42       630\n",
            "\n",
            "    accuracy                           0.38      4366\n",
            "   macro avg       0.39      0.38      0.39      4366\n",
            "weighted avg       0.39      0.38      0.38      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e758d13027494c35a89baa465e40fe2f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=8 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/fd1f057a772649038c3a5d72f69503ee\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3918918918918919\n",
            "Precision: 0.40079655552655574\n",
            "Recall: 0.3952038337841653\n",
            "F1 Score: 0.3954075900905528\n",
            "AUC Score: 0.7382885971965507\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.45      0.35      0.40       661\n",
            "     disgust       0.52      0.51      0.51       534\n",
            "        fear       0.38      0.40      0.39       634\n",
            "       happy       0.34      0.37      0.36       634\n",
            "     neutral       0.30      0.39      0.34       620\n",
            "         sad       0.39      0.31      0.35       653\n",
            "    surprise       0.42      0.43      0.43       630\n",
            "\n",
            "    accuracy                           0.39      4366\n",
            "   macro avg       0.40      0.40      0.40      4366\n",
            "weighted avg       0.40      0.39      0.39      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30ba9aff29f349f5b2f1ea05d9512279",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=9 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/57532e7c1632447ab319d1612a0710e5\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.38456252863032525\n",
            "Precision: 0.39563121052648736\n",
            "Recall: 0.3870029654772559\n",
            "F1 Score: 0.3881806756229632\n",
            "AUC Score: 0.7351018966435883\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.42      0.35      0.38       661\n",
            "     disgust       0.54      0.46      0.50       534\n",
            "        fear       0.36      0.36      0.36       634\n",
            "       happy       0.33      0.38      0.35       634\n",
            "     neutral       0.33      0.44      0.38       620\n",
            "         sad       0.40      0.32      0.36       653\n",
            "    surprise       0.40      0.40      0.40       630\n",
            "\n",
            "    accuracy                           0.38      4366\n",
            "   macro avg       0.40      0.39      0.39      4366\n",
            "weighted avg       0.39      0.38      0.39      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8590dbf468946ed90d134e5e2a06850",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=10 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/6ea61f3e862a4fc5bbdadbac679f732d\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3985341273476867\n",
            "Precision: 0.4055017723886456\n",
            "Recall: 0.40106092945873345\n",
            "F1 Score: 0.401009115259094\n",
            "AUC Score: 0.7437075622028809\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.41      0.31      0.35       661\n",
            "     disgust       0.52      0.48      0.50       534\n",
            "        fear       0.36      0.40      0.38       634\n",
            "       happy       0.36      0.38      0.37       634\n",
            "     neutral       0.33      0.40      0.37       620\n",
            "         sad       0.42      0.36      0.39       653\n",
            "    surprise       0.44      0.47      0.46       630\n",
            "\n",
            "    accuracy                           0.40      4366\n",
            "   macro avg       0.41      0.40      0.40      4366\n",
            "weighted avg       0.40      0.40      0.40      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c8364b95b27449fa3e99d0b9baac4a6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=11 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/4077c3628d9148d392d1ed14a9b11fd4\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3783783783783784\n",
            "Precision: 0.3867571236213267\n",
            "Recall: 0.3813648402154365\n",
            "F1 Score: 0.38154419822246727\n",
            "AUC Score: 0.7341728352295253\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.39      0.30      0.34       661\n",
            "     disgust       0.50      0.48      0.49       534\n",
            "        fear       0.35      0.37      0.36       634\n",
            "       happy       0.33      0.38      0.36       634\n",
            "     neutral       0.29      0.37      0.33       620\n",
            "         sad       0.42      0.34      0.37       653\n",
            "    surprise       0.43      0.44      0.43       630\n",
            "\n",
            "    accuracy                           0.38      4366\n",
            "   macro avg       0.39      0.38      0.38      4366\n",
            "weighted avg       0.38      0.38      0.38      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "61e6e52be0d04fbea0dffc822f3d4b73",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=12 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/6cbe6fc47e1c47c098d81a952acd6a03\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3760879523591388\n",
            "Precision: 0.3817634271391193\n",
            "Recall: 0.3784958694635025\n",
            "F1 Score: 0.3788903689228461\n",
            "AUC Score: 0.7323726168157021\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.38      0.32      0.35       661\n",
            "     disgust       0.49      0.46      0.47       534\n",
            "        fear       0.35      0.38      0.36       634\n",
            "       happy       0.36      0.37      0.37       634\n",
            "     neutral       0.31      0.38      0.34       620\n",
            "         sad       0.36      0.32      0.34       653\n",
            "    surprise       0.41      0.42      0.42       630\n",
            "\n",
            "    accuracy                           0.38      4366\n",
            "   macro avg       0.38      0.38      0.38      4366\n",
            "weighted avg       0.38      0.38      0.38      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4d9d173a17d46208c04f5d5d09d61e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=13 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/fe453ce54dad45cabc3154d638cc2465\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n",
            "Accuracy: 0.3868529546495648\n",
            "Precision: 0.3940975403116174\n",
            "Recall: 0.3897644075151687\n",
            "F1 Score: 0.389558539467925\n",
            "AUC Score: 0.7338623819623314\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.39      0.31      0.34       661\n",
            "     disgust       0.54      0.48      0.50       534\n",
            "        fear       0.37      0.40      0.38       634\n",
            "       happy       0.35      0.37      0.36       634\n",
            "     neutral       0.33      0.39      0.36       620\n",
            "         sad       0.39      0.32      0.35       653\n",
            "    surprise       0.40      0.47      0.43       630\n",
            "\n",
            "    accuracy                           0.39      4366\n",
            "   macro avg       0.39      0.39      0.39      4366\n",
            "weighted avg       0.39      0.39      0.39      4366\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a764b8a0aa9f467192e9018c8c05a51d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ğŸƒ View run KNN StratifiedKFold=14 at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18/runs/30e5ac1368194bdfb97badbf86c3f760\n",
            "ğŸ§ª View experiment at: https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow/#/experiments/18\n"
          ]
        }
      ],
      "source": [
        "images = np.load('C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\FER2013\\\\combined\\\\images.npy')\n",
        "labels = np.load('C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\FER2013\\\\combined\\\\labels.npy')\n",
        "\n",
        "N_NEIGHBORS = 9\n",
        "WEIGHTS = 'distance'\n",
        "METRIC = 'manhattan'\n",
        "ALGORITHM = 'auto'\n",
        "TEST_SIZE = 0.8\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS = 15\n",
        "SHUFFLE = True\n",
        "\n",
        "model_params = {\n",
        "  'n_neighbors': N_NEIGHBORS,\n",
        "  'weights': WEIGHTS,\n",
        "  'metric': METRIC,\n",
        "  'algorithm': ALGORITHM\n",
        "}\n",
        "\n",
        "calib_params = {\n",
        "  'test_size': TEST_SIZE,\n",
        "  'random_state': RANDOM_STATE\n",
        "}\n",
        "\n",
        "kfold_params = {\n",
        "    'n_splits': N_SPLITS,\n",
        "    'shuffle': SHUFFLE\n",
        "}\n",
        "\n",
        "skf = StratifiedKFold(**kfold_params)\n",
        "i = 0\n",
        "\n",
        "for train_idx, test_idx in skf.split(images, labels):\n",
        "  X_train, X_test = images[train_idx], images[test_idx]\n",
        "  y_train, y_test = labels[train_idx], labels[test_idx]\n",
        "\n",
        "  X_calib, X_test, y_calib, y_test = train_test_split(X_test, y_test, **calib_params)\n",
        "\n",
        "  model = KNeighborsClassifier(**model_params)\n",
        "  model.fit(X_train, y_train)\n",
        "\n",
        "  calib_model = CalibratedClassifierCV(model, cv=\"prefit\")\n",
        "  calib_model.fit(X_calib, y_calib)\n",
        "\n",
        "  predict = calib_model.predict(X_test)\n",
        "  predict_proba = calib_model.predict_proba(X_test)\n",
        "\n",
        "  metrics = {\n",
        "    'accuracy': accuracy_score(y_test, predict),\n",
        "    'precision': precision_score(y_test, predict, average='macro'),\n",
        "    'recall': recall_score(y_test, predict, average='macro'),\n",
        "    'f1': f1_score(y_test, predict, average='macro'),\n",
        "    'auc_score': roc_auc_score(y_test, predict_proba, multi_class='ovr', average='macro')\n",
        "  }\n",
        "\n",
        "  print(f\"Accuracy: {metrics['accuracy']}\\nPrecision: {metrics['precision']}\\nRecall: {metrics['recall']}\\nF1 Score: {metrics['f1']}\\nAUC Score: {metrics['auc_score']}\")\n",
        "  report = classification_report(y_test, predict)\n",
        "  print(report)\n",
        "\n",
        "  mlflow.set_experiment(\"KNN_Model FER2013 augmented\")\n",
        "  mlflow.set_tracking_uri(\"https://dagshub.com/IdjiotSandwiches/face-emotion-recognition.mlflow\")\n",
        "\n",
        "  with mlflow.start_run(run_name=f'KNN StratifiedKFold={i}'):\n",
        "    mlflow.log_params(gabor_params)\n",
        "    mlflow.log_params(calib_params)\n",
        "    mlflow.log_params(model_params)\n",
        "    mlflow.log_params(kfold_params)\n",
        "    mlflow.log_param('floating_point', FLOATING_POINT)\n",
        "    mlflow.log_param('image_size', IMAGE_SIZE)\n",
        "    mlflow.log_param('PCA_n_components', N_COMPONENTS)\n",
        "    mlflow.log_param('gaussian_blur', BLUR)\n",
        "    mlflow.log_metrics(metrics)\n",
        "    mlflow.sklearn.log_model(\n",
        "        sk_model=calib_model,\n",
        "        artifact_path='KNN Model',\n",
        "        input_example=X_train[:1]\n",
        "    )\n",
        "  i = i + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slTaWKZH_JzJ"
      },
      "source": [
        "## **Testing images shape**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItH1jRHKHaO8",
        "outputId": "9e687199-6c9b-48cb-eac9-753f8006b5f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Explained variance ratio: [0.51456678 0.21078003 0.15307621 0.05976604 0.0324442  0.01573344\n",
            " 0.0074042  0.00312239 0.00156306 0.00067005]\n",
            "Cumulative explained variance: [0.51456678 0.72534682 0.87842302 0.93818907 0.97063326 0.9863667\n",
            " 0.9937709  0.9968933  0.99845636 0.99912641]\n",
            "(1, 1280)\n"
          ]
        }
      ],
      "source": [
        "images_ = []\n",
        "# img = cv.imread(f'facial-emotion-recognition-augmented/disgust/disgust_1022.png', cv.IMREAD_GRAYSCALE)\n",
        "# img = cv.imread(f'C:\\\\Users\\\\vinar\\\\Downloads\\\\RAF-DB\\\\test\\\\fear\\\\test_2253_aligned.jpg', cv.IMREAD_GRAYSCALE)\n",
        "img = cv.imread(f'../neutral_3.png', cv.IMREAD_GRAYSCALE)\n",
        "img = cv.resize(img, (100,100))\n",
        "img = cv.GaussianBlur(img,(5,5),0)\n",
        "img = cv.equalizeHist(img)\n",
        "img = img / 255.0\n",
        "img = gabor_filter(img)\n",
        "img = np.array(img)\n",
        "img = img.reshape(img.shape[0],-1)\n",
        "pca = PCA(n_components=10)\n",
        "img = pca.fit_transform(img)\n",
        "img = img.reshape(-1)\n",
        "images_.append(img)\n",
        "images_ = np.array(images_)\n",
        "\n",
        "print(\"Explained variance ratio:\", pca.explained_variance_ratio_)\n",
        "print(\"Cumulative explained variance:\", np.cumsum(pca.explained_variance_ratio_))\n",
        "\n",
        "print(images_.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c565ed69882464ca452f8926a00be20",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "logged_model = 'runs:/14b06e579a264caab691033399c45ceb/KNN Model'\n",
        "model = mlflow.pyfunc.load_model(logged_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "nGxyJjAVKtI-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "happy\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict(images_)\n",
        "for p in prediction:\n",
        "  print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZagJKOZm6-M"
      },
      "source": [
        "## **Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBFlRWwj_XiC"
      },
      "source": [
        "### **Without PCA**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijdkLu6IALkD",
        "outputId": "0e53f53a-b561-446f-998f-5eb94bc3f88b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 120 candidates, totalling 360 fits\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=3, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=3, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=3, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=3, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=3, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=3, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=5, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=5, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=5, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=5, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=7, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=7, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=7, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=7, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=7, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=7, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=9, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=9, weights=uniform; total time=   0.2s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=9, weights=uniform; total time=   0.3s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=9, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=9, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=9, weights=distance; total time=   0.0s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.3s\n",
            "[CV] END algorithm=auto, metric=minkowski, n_neighbors=11, weights=uniform; total time=   0.2s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 41\u001b[0m\n\u001b[0;32m     32\u001b[0m model \u001b[38;5;241m=\u001b[39m KNeighborsClassifier()\n\u001b[0;32m     33\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     34\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mmodel, \n\u001b[0;32m     35\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mmodel_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     40\u001b[0m )\n\u001b[1;32m---> 41\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid\u001b[38;5;241m.\u001b[39mbest_estimator_)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(grid\u001b[38;5;241m.\u001b[39mbest_params_)\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    960\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    962\u001b[0m         )\n\u001b[0;32m    963\u001b[0m     )\n\u001b[1;32m--> 965\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    984\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m     )\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:910\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    907\u001b[0m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_error\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    909\u001b[0m fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m--> 910\u001b[0m test_scores \u001b[38;5;241m=\u001b[39m \u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    911\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscore_params_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\n\u001b[0;32m    912\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    913\u001b[0m score_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time \u001b[38;5;241m-\u001b[39m fit_time\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_train_score:\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971\u001b[0m, in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, score_params, error_score)\u001b[0m\n\u001b[0;32m    969\u001b[0m         scores \u001b[38;5;241m=\u001b[39m scorer(estimator, X_test, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscore_params)\n\u001b[0;32m    970\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 971\u001b[0m         scores \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mscore_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _MultimetricScorer):\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;66;03m# If `_MultimetricScorer` raises exception, the `error_score`\u001b[39;00m\n\u001b[0;32m    975\u001b[0m         \u001b[38;5;66;03m# parameter is equal to \"raise\".\u001b[39;00m\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:139\u001b[0m, in \u001b[0;36m_MultimetricScorer.__call__\u001b[1;34m(self, estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scorer, _BaseScorer):\n\u001b[1;32m--> 139\u001b[0m         score \u001b[38;5;241m=\u001b[39m \u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcached_call\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m         score \u001b[38;5;241m=\u001b[39m scorer(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mget(name)\u001b[38;5;241m.\u001b[39mscore)\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:371\u001b[0m, in \u001b[0;36m_Scorer._score\u001b[1;34m(self, method_caller, estimator, X, y_true, **kwargs)\u001b[0m\n\u001b[0;32m    369\u001b[0m pos_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m is_regressor(estimator) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pos_label()\n\u001b[0;32m    370\u001b[0m response_method \u001b[38;5;241m=\u001b[39m _check_response_method(estimator, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_method)\n\u001b[1;32m--> 371\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmethod_caller\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    375\u001b[0m scoring_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sign \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_score_func(y_true, y_pred, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mscoring_kwargs)\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py:89\u001b[0m, in \u001b[0;36m_cached_call\u001b[1;34m(cache, estimator, response_method, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response_method \u001b[38;5;129;01min\u001b[39;00m cache:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cache[response_method]\n\u001b[1;32m---> 89\u001b[0m result, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_get_response_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     cache[response_method] \u001b[38;5;241m=\u001b[39m result\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\utils\\_response.py:211\u001b[0m, in \u001b[0;36m_get_response_values\u001b[1;34m(estimator, X, response_method, pos_label, return_response_method_used)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m target_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    209\u001b[0m         pos_label \u001b[38;5;241m=\u001b[39m classes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 211\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mprediction_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_log_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    214\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m _process_predict_proba(\n\u001b[0;32m    215\u001b[0m         y_pred\u001b[38;5;241m=\u001b[39my_pred,\n\u001b[0;32m    216\u001b[0m         target_type\u001b[38;5;241m=\u001b[39mtarget_type,\n\u001b[0;32m    217\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m    218\u001b[0m         pos_label\u001b[38;5;241m=\u001b[39mpos_label,\n\u001b[0;32m    219\u001b[0m     )\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py:271\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[1;32m--> 271\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:903\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[0;32m    899\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    900\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor set algorithm=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrute\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_method\n\u001b[0;32m    902\u001b[0m         )\n\u001b[1;32m--> 903\u001b[0m     chunked_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    904\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_tree_query_parallel_helper\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    905\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\n\u001b[0;32m    906\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    907\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    908\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minternal: _fit_method not recognized\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    134\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\PythonProject\\env\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:704\u001b[0m, in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_tree_query_parallel_helper\u001b[39m(tree, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    699\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Helper for the Parallel calls in KNeighborsMixin.kneighbors.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \n\u001b[0;32m    701\u001b[0m \u001b[38;5;124;03m    The Cython method tree.query is not directly picklable by cloudpickle\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;124;03m    under PyPy.\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "images = np.load('C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\FER2013\\\\new\\\\images.npy')\n",
        "labels = np.load('C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\FER2013\\\\new\\\\labels.npy')\n",
        "\n",
        "N_NEIGHBORS = [3,5,7,9,11]\n",
        "WEIGHTS = ['uniform', 'distance']\n",
        "METRIC = ['minkowski', 'euclidean', 'manhattan']\n",
        "ALGORITHM = ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
        "\n",
        "TEST_SIZE = 0.2\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "split_params = {\n",
        "    'test_size': TEST_SIZE,\n",
        "    'random_state': RANDOM_STATE\n",
        "}\n",
        "\n",
        "model_params = {\n",
        "    'n_neighbors': N_NEIGHBORS,\n",
        "    'weights': WEIGHTS,\n",
        "    'metric': METRIC,\n",
        "    'algorithm': ALGORITHM\n",
        "}\n",
        "\n",
        "scoring = {\n",
        "    'accuracy': 'accuracy',\n",
        "    # 'roc_auc': 'roc_auc'\n",
        "}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, **split_params, stratify=labels)\n",
        "# X_test, X_calib, y_test, y_calib = train_test_split(X_test, y_test, **calib_params, stratify=y_test)\n",
        "\n",
        "model = KNeighborsClassifier()\n",
        "grid = GridSearchCV(\n",
        "    estimator=model, \n",
        "    param_grid=model_params,\n",
        "    scoring=scoring,\n",
        "    refit='accuracy',\n",
        "    cv=3,\n",
        "    verbose=2\n",
        ")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(grid.best_estimator_)\n",
        "print(grid.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhUL6_0i_cHW"
      },
      "source": [
        "### **Using calibration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "kicKUxC8dKeH",
        "outputId": "d859b114-6888-449f-9d28-c9a2126b2251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.31209362808842656\n",
            "Precision: 0.3955131143254627\n",
            "Recall: 0.28298242490642067\n",
            "F1 Score: 0.3025389865580613\n",
            "ROC_AUC Score: 0.6350601746255912\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.32      0.15      0.21       743\n",
            "     disgust       0.80      0.29      0.43        82\n",
            "        fear       0.30      0.18      0.22       768\n",
            "       happy       0.30      0.64      0.40      1348\n",
            "     neutral       0.28      0.18      0.22       930\n",
            "         sad       0.26      0.18      0.21       911\n",
            "    surprise       0.51      0.36      0.42       601\n",
            "\n",
            "    accuracy                           0.31      5383\n",
            "   macro avg       0.40      0.28      0.30      5383\n",
            "weighted avg       0.32      0.31      0.29      5383\n",
            "\n"
          ]
        }
      ],
      "source": [
        "images = np.load('C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\FER2013\\\\new\\\\images.npy')\n",
        "labels = np.load('C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\FER2013\\\\new\\\\labels.npy')\n",
        "\n",
        "N_NEIGHBORS = 9\n",
        "WEIGHTS = 'distance'\n",
        "METRIC = 'manhattan'\n",
        "ALGORITHM = 'auto'\n",
        "\n",
        "TEST_SIZE = 0.3\n",
        "CALIB_SIZE = 0.5\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "split_params = {\n",
        "    'test_size': TEST_SIZE,\n",
        "    'random_state': RANDOM_STATE\n",
        "}\n",
        "\n",
        "calib_params = {\n",
        "    'test_size': CALIB_SIZE,\n",
        "    'random_state': RANDOM_STATE\n",
        "}\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, **split_params, stratify=labels)\n",
        "X_test, X_calib, y_test, y_calib = train_test_split(X_test, y_test, **calib_params, stratify=y_test)\n",
        "\n",
        "model_params = {\n",
        "  'n_neighbors': N_NEIGHBORS,\n",
        "  'weights': WEIGHTS,\n",
        "  'metric': METRIC,\n",
        "  'algorithm': ALGORITHM\n",
        "}\n",
        "\n",
        "model = KNeighborsClassifier(**model_params)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "calib_model = CalibratedClassifierCV(model, cv=\"prefit\")\n",
        "calib_model.fit(X_calib, y_calib)\n",
        "\n",
        "predict = calib_model.predict(X_test)\n",
        "predict_proba = calib_model.predict_proba(X_test)\n",
        "\n",
        "metrics = {\n",
        "  'accuracy': accuracy_score(y_test, predict),\n",
        "  'precision': precision_score(y_test, predict, average='macro'),\n",
        "  'recall': recall_score(y_test, predict, average='macro'),\n",
        "  'f1': f1_score(y_test, predict, average='macro'),\n",
        "  'auc_score': roc_auc_score(y_test, predict_proba, multi_class='ovr', average='macro')\n",
        "}\n",
        "\n",
        "print(f\"Accuracy: {metrics['accuracy']}\\nPrecision: {metrics['precision']}\\nRecall: {metrics['recall']}\\nF1 Score: {metrics['f1']}\\nROC_AUC Score: {metrics['auc_score']}\")\n",
        "print(classification_report(y_test, predict))\n",
        "\n",
        "# mlflow.set_experiment(\"KNN_Model using calibration\")\n",
        "# mlflow.set_tracking_uri(\"https://dagshub.com/IdjiotSandwiches/knn-fer.mlflow\")\n",
        "\n",
        "# with mlflow.start_run(run_name=f'KNN sigma=5'):\n",
        "#   mlflow.log_params(gabor_params)\n",
        "#   mlflow.log_params(split_params)\n",
        "#   mlflow.log_param('calib_test_size', calib_params['test_size'])\n",
        "#   mlflow.log_param('calib_random_state', calib_params['random_state'])\n",
        "#   mlflow.log_params(model_params)\n",
        "#   mlflow.log_metrics(metrics)\n",
        "#   mlflow.sklearn.log_model(\n",
        "#       sk_model=calib_model,\n",
        "#       artifact_path='KNN Model',\n",
        "#       input_example=X_train[:1]\n",
        "#   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### **Tuning k Value**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimal k: 1\n"
          ]
        }
      ],
      "source": [
        "images = np.load('C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\images.npy')\n",
        "labels = np.load('C:\\\\Users\\\\vinar\\\\Downloads\\\\gabor-filtered-imgs\\\\labels.npy')\n",
        "\n",
        "N_NEIGHBORS = range(1,21)\n",
        "WEIGHTS = 'distance'\n",
        "METRIC = 'manhattan'\n",
        "ALGORITHM = 'ball_tree'\n",
        "TEST_SIZE = 0.5\n",
        "RANDOM_STATE = 42\n",
        "N_SPLITS = 10\n",
        "SHUFFLE = True\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, random_state=RANDOM_STATE, test_size=0.2)\n",
        "\n",
        "def evaluate_knn(k):\n",
        "    model_params = {\n",
        "        'n_neighbors': k,\n",
        "        'weights': WEIGHTS,\n",
        "        'metric': METRIC,\n",
        "        'algorithm': ALGORITHM\n",
        "    }\n",
        "    model = KNeighborsClassifier(**model_params)\n",
        "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    return cv_scores.mean()\n",
        "\n",
        "# Parallel execution\n",
        "scores = Parallel(n_jobs=4)(delayed(evaluate_knn)(k) for k in N_NEIGHBORS)\n",
        "\n",
        "# Find optimal k\n",
        "optimal_k = N_NEIGHBORS[scores.index(max(scores))]\n",
        "print(f\"Optimal k: {optimal_k}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJhef8Rx_fdX"
      },
      "source": [
        "## **Prediction result**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdWcylVFCQBp",
        "outputId": "0f735825-cbda-4bd5-8bcb-379d20b9cb35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1120\n"
          ]
        }
      ],
      "source": [
        "not_same = []\n",
        "\n",
        "for p, y in zip(predict, y_test):\n",
        "  if(p != y):\n",
        "    not_same.append(p)\n",
        "\n",
        "print(len(not_same))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNZO49Fgohu3fAShmdkoQPd",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (External Venv)",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4d8ec34e0e8b46eea1f0c715cc9a0313": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "920e17e50eb74233a60169339897c634": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4d8ec34e0e8b46eea1f0c715cc9a0313",
            "msg_id": "",
            "outputs": [
              {
                "data": {
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">â </span> Waiting for authorization\n</pre>\n",
                  "text/plain": "\u001b[32mâ \u001b[0m Waiting for authorization\n"
                },
                "metadata": {},
                "output_type": "display_data"
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
